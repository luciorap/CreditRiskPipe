{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b57e068",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Here a Use a Sklearn Pipeline to automate the cleaning, standardizing and training Of A Logistic Regression\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src import config, data_utils\n",
    "\n",
    "app_train, app_test, columns_description = data_utils.get_datasets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d76372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show distribution of target variable \n",
    "\n",
    "df = app_train.reset_index().groupby(['TARGET']).size().to_frame('Total')\n",
    "\n",
    "df['Percentage'] = df['Total'].div(df['Total'].sum()).mul(100)\n",
    "\n",
    "print(df)\n",
    "\n",
    "sns.barplot(x='Total', y='Percentage', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe601023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use MatPlotLib to Plot For Example = the family status of the applicants.\n",
    "\n",
    "df = app_train.groupby(['NAME_FAMILY_STATUS']).size().to_frame('TotalFS').reset_index('NAME_FAMILY_STATUS')\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "ax =sns.barplot(x='NAME_FAMILY_STATUS', y='TotalFS', data=df)\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5eecdf-ee08-4ebd-8667-25cdb9a3eef4",
   "metadata": {
    "id": "5a5eecdf-ee08-4ebd-8667-25cdb9a3eef4"
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train, y_train, X_test, y_test = data_utils.get_feature_target(app_train, app_test)\n",
    "\n",
    "X_train, X_val, y_train, y_val = data_utils.get_train_val_sets(X_train, y_train)\n",
    "\n",
    "# Set the Columns For Categorical\n",
    "\n",
    "ordinal_features = X_train.select_dtypes(include=[\"object\"]).nunique()==2\n",
    "ordinal_columns = ordinal_features[ordinal_features].index.tolist()\n",
    "\n",
    "onehot_features = X_train.select_dtypes(include=[\"object\"]).nunique() > 2\n",
    "onehot_columns = onehot_features[onehot_features].index.tolist()\n",
    "\n",
    "# Set the Pipeline\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(missing_values=np.nan, strategy=\"median\")),\n",
    "    ('scaler', MinMaxScaler())],           \n",
    ")\n",
    "\n",
    "categorical_ord_transformer = Pipeline(\n",
    "    steps=[\n",
    "    ('imputerall', SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")),           \n",
    "    (\"ordinal\", OrdinalEncoder()),\n",
    "    ('scaler', MinMaxScaler()),           \n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "    ('imputerall', SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")),           \n",
    "    (\"encoder\", OneHotEncoder(drop='first',sparse_output=False)),\n",
    "    ('scaler', MinMaxScaler()),           \n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, selector(dtype_exclude=\"object\") ),\n",
    "        (\"catord\", categorical_ord_transformer, ordinal_columns ),\n",
    "        (\"cat\", categorical_transformer, onehot_columns ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Preprocess all the data\n",
    "\n",
    "pipe = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), \n",
    "    (\"classifier\", LogisticRegression(C=0.0001))]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Predict \n",
    "\n",
    "roc_auc_pipe = pipe.predict_proba(X_train)[:, 1]\n",
    "roc_auc_pipe\n",
    "\n",
    "print(f\"Train ROC AUC Score: {roc_auc_pipe[4]}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "942da44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC AUC Score: 0.01378937407056915\n"
     ]
    }
   ],
   "source": [
    "### In this a Make my own experimentation process with Another Model\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import numpy as np\n",
    "from src import config, data_utils\n",
    "\n",
    "app_train, app_test, columns_description = data_utils.get_datasets()\n",
    "\n",
    "# Assign to X_train all the columns from app_train except \"TARGET\", \"DAYS_EMPLOYED\", \"CODE_GENDER\"\n",
    "X_train = app_train.drop([\"DAYS_EMPLOYED\",\"TARGET\",\"CODE_GENDER\"], axis=1)\n",
    "\n",
    "# Assign to y_train the \"TARGET\" column\n",
    "y_train = app_train[\"TARGET\"]\n",
    "\n",
    "# Assign to X_test all the columns from app_test except \"TARGET\"\n",
    "X_test = app_test.drop([\"DAYS_EMPLOYED\",\"TARGET\",\"CODE_GENDER\"], axis=1)\n",
    "\n",
    "# Assign to y_test the \"TARGET\" column\n",
    "y_test = app_test[\"TARGET\"]\n",
    "\n",
    "# Split Train and Test Data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "# Set the Pipeline\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(missing_values=np.nan, strategy=\"median\")), (\"scaler\", StandardScaler())],\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder(drop='first',sparse_output=False)),\n",
    "        (\"scaler\", StandardScaler()),        \n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, selector(dtype_exclude=\"object\")),\n",
    "        (\"cat\", categorical_transformer, selector(dtype_include=\"object\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Preprocess all the data\n",
    "\n",
    "clf = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), \n",
    "    (\"classifier\", DecisionTreeClassifier(random_state=0, max_depth=10))]\n",
    ")\n",
    "\n",
    "# Fit The Model \n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "roc_auc_pipe = clf.predict_proba(X_train)[:, 1]\n",
    "roc_auc_pipe\n",
    "\n",
    "print(f\"Train ROC AUC Score: {roc_auc_pipe[1]}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f863b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In a Plus I Train a LightGBM model\n",
    "\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "\n",
    "from src import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d1b40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preproccessing For The Train Data\n",
    "train_data, val_data, test_data = preprocessing.preprocess_data(X_train, X_val, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c88a030",
   "metadata": {},
   "outputs": [],
   "source": [
    "### See How It Performs\n",
    "\n",
    "gbm = lgb.LGBMClassifier(learning_rate=0.2, first_metric_only = True)\n",
    "\n",
    "gbm.fit(train_data, y_train,eval_set =[(test_data,y_test)] , eval_metric=['auc'], callbacks=[lgb.early_stopping(stopping_rounds=100)])\n",
    "\n",
    "best_credit_model_ever = gbm\n",
    "\n",
    "test_preds = best_credit_model_ever.predict_proba(test_data)[:, 1]\n",
    "test_preds"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
